---
import Header from '~/components/widgets/Header.astro';
import Hero2 from '~/components/widgets/Hero2.astro';
import Content from '~/components/widgets/Content.astro';
// import Timeline from '~/components/ui/Timeline.astro';
import FAQs from '~/components/widgets/FAQs.astro';
// import Brands from '~/components/widgets/Brands.astro';
// import Timezone from '~/components/widgets/Timezone.astro';
import Layout from '~/layouts/PageLayout.astro';
import Testimonials from '~/components/widgets/Testimonials.astro';
import Track2 from '~/components/widgets/Track2.astro';
import Track3 from '~/components/widgets/Track3.astro';
import Track1 from '~/components/widgets/Track1.astro';
import { getPermalink } from '~/utils/permalinks';
// import Sponsor from '~/components/widgets/Sponsor.astro';

const metadata = {
  title: 'Challenges',
};

const headerData = {
  links: [
    {
      text: 'Overview',
      href: getPermalink('/challenges#Overview'),
    },
    {
      text: 'TRACK1',
      href: getPermalink('/challenges#TRACK1'),
    },
    {
      text: 'TRACK2',
      href: getPermalink('/challenges#TRACK2'),
    },
    {
      text: 'TRACK3',
      href: getPermalink('/challenges#TRACK3'),
    },
    {
      text: 'Home',
      href: getPermalink('/'),
    },
  ],
};
---

<Layout metadata={metadata}>
  <Fragment slot="header">
    <Header {...headerData} isSticky />
  </Fragment>

  <!-- Hero2 Widget ******************* -->

  <Hero2
    tagline="ICML 2024 Workshop"
    actions={[{ variant: 'primary', text: 'Get Started', href: 'https://icml.cc/virtual/2024/workshop/29951' }]}
  >
    <Fragment slot="title">Trustworthy Multi-modal Foundation Models and AI Agents (TiFA) Challenges</Fragment>
  </Hero2>

  <!-- Content Widget **************** -->

  <Content id="Overview" classes={{ container: 'pb-0 md:pb-0 lg:pb-0' }}>
    <Fragment slot="title"> Overview </Fragment><Fragment slot="subtitle"
      >Welcome to the ICML 2024 Workshop on Trustworthy in Multi-modal Foundation Models and AI Agents (TiFA)
    </Fragment>
    <Fragment slot="content"> </Fragment>
  </Content>

  <Testimonials
    classes={{ container: 'py-0 md:py-0 lg:py-0 ' }}
    testimonials={[
      {
        title: 'Track 1',
        name: 'Attack Challenge',
        image: {
          src: '/track1.png',
          alt: 'Track 1',
        },
        link: '#TRACK1',
        job: 'Multimodal large language models (MLLMs), which are capable of processing images and performing visual question-and-answer tasks, may generate harmful content if the input image or text contains inducing or harmful properties. Furthermore, the introduction of perturbations to images or texts can degrade the performance of these models in various visual tasks, such as object counting and reasoning. This necessitates an investigation into the effects of different input perturbations or attack methods on the performance and trustworthiness of multimodal large models. Understanding these impacts is crucial for developing strategies to mitigate potential risks associated with MLLMs.',
      },
      {
        title: 'Track 2',
        name: 'Defense Challenge',
        image: {
          src: '/track2.png',
          alt: 'Track 2',
        },
        link: '#TRACK2',
        job: 'Multimodal Large Language Models (MLLMs) possess the capability to process images and perform visual question-and-answer tasks. However, when input images or texts contain malicious content or are subtly altered through perturbations, MLLMs can generate harmful responses or experience degraded performance across various visual tasks. This vulnerability represents a significant challenge to the trustworthiness and safety of MLLMs, underscoring the need for robust defense mechanisms. The primary goal of this challenge is to devise innovative strategies and techniques to safeguard MLLMs against attacks that leverage their multimodal capabilities.',
      },
      {
        title: 'Track 3',
        name: 'Agent Trustworthy Challenge',
        image: {
          src: '/track3.png',
          alt: 'Track 3',
        },
        link: '#TRACK3',
        job: "The evolution of Artificial Intelligence (AI) reflects its increasing capability and integration into our daily lives, from basic automated tools to sophisticated, autonomous systems. Initially, AI systems were simple agents performing goal-directed actions without specific human commands. Over time, these evolved into Large Language Models (LLMs) like GPT-4, which not only execute complex tasks but also enhance decision-making through advanced language understanding and generation capabilities. The most advanced tier of AI development includes ethically aligned, trustworthy agents. These agents are designed to operate reliably within ethical and safety frameworks, illustrating both the benefits and the essential need to manage the risks associated with AI's integration into society. This tiered framework—from basic agents, through linguistically skilled LLMs, to ethically guided trustworthy agents—underscores the progression and potential of AI in enhancing human capabilities and addressing complex challenges.",
      },
    ]}
  />
  <Track1 title="Attack Challenge" tagline="Track 1" id="TRACK1" />
  <Track2 title="Defense Challenge" tagline="Track 2" id="TRACK2" />
  <Track3 title="Agent Trustworthy Challenge" tagline="Track 3" id="TRACK3" />
  <FAQs
    title="Frequently Asked Questions"
    items={[
      {
        title: 'Can we submit a paper that will also be submitted to NeurIPS 2024?',
        description: 'Yes.',
        icon: 'tabler:help-octagon',
      },
      {
        title: 'Can we submit a paper that was accepted at ICLR 2024?',
        description: 'No. ICML prohibits main conference publication from appearing concurrently at the workshops.',
        icon: 'tabler:help-octagon',
      },
      {
        title: 'Will the reviews be made available to authors?',
        description: 'Yes.',
        icon: 'tabler:help-octagon',
      },
      {
        title: 'I have a question not addressed here, whom should I contact?',
        description: 'Email organizers at icml-tifa-workshop@googlegroups.com',
        icon: 'tabler:help-octagon',
      },
    ]}
  />
</Layout>
