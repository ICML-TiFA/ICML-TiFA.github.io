---
import Header from '~/components/widgets/Header.astro';
import Hero2 from '~/components/widgets/Hero2.astro';
import Content from '~/components/widgets/Content.astro';
// import Timeline from '~/components/ui/Timeline.astro';
import FAQs from '~/components/widgets/FAQs.astro';
// import Brands from '~/components/widgets/Brands.astro';
// import Timezone from '~/components/widgets/Timezone.astro';
import Layout from '~/layouts/PageLayout.astro';
import Testimonials from '~/components/widgets/Testimonials.astro';
import Track2 from '~/components/widgets/Track2.astro';
import Track3 from '~/components/widgets/Track3.astro';
import Track1 from '~/components/widgets/Track1.astro';
import { getPermalink } from '~/utils/permalinks';
// import Sponsor from '~/components/widgets/Sponsor.astro';

const metadata = {
  title: 'Challenges',
};

const headerData = {
  links: [
    {
      text: 'Overview',
      href: getPermalink('/challenges#Overview'),
    },
    {
      text: 'TRACKI',
      href: getPermalink('/challenges#TRACK1'),
    },
    // {
    //   text: 'TRACK2',
    //   href: getPermalink('/challenges#TRACK2'),
    // },
    {
      text: 'TRACKII',
      href: getPermalink('/challenges#TRACK2'),
    },
    {
      text: 'Home',
      href: getPermalink('/'),
    },
  ],
};
---

<Layout metadata={metadata}>
  <Fragment slot="header">
    <Header {...headerData} isSticky />
  </Fragment>

  <!-- Hero2 Widget ******************* -->

  <Hero2
    tagline="ICML 2024 Workshop"
    actions={[{ variant: 'primary', text: 'Get Started', href: 'https://icml.cc/virtual/2024/workshop/29951' }]}
  >
    <Fragment slot="title">Trustworthy Multi-modal Foundation Models and AI Agents (TiFA) Challenges</Fragment>
  </Hero2>

  <!-- Content Widget **************** -->

  <Content id="Overview" classes={{ container: 'pb-0 md:pb-0 lg:pb-0' }}>
    <Fragment slot="title"> General Rules and Policy of TiFA Challenge </Fragment>
    <Fragment slot="content">
      <h1 class="font-bold text-4xl text-center">General Introduction</h1>
      <br />
      <p>
        Our challenge will be a competition featuring two main tasks designed to advance the field of multimodal
        language model trustworthiness and the development of trustworthy agents. Both challenges aim to deepen our
        understanding of AI robustness and trustworthiness, leveraging cutting-edge datasets and evaluation methods. We
        invite researchers and practitioners from around the world to participate, contribute, and push the boundaries
        of what is possible in the realm of trustworthy AI systems.
      </p>
      <br />
      <h1 class="font-bold text-4xl text-center">Policies</h1>
      <br />
      <h1 class="text-2xl font-bold">Deadlines:</h1>
      <p>
        All deadlines (including challenge results submission, research proposals and winner technical reports) are
        strict. In no circumstances will extensions be given.
      </p>
      <h1 class="text-2xl font-bold">Ethics:</h1>
      <p>
        Authors and members of the program committee, including reviewers, are expected to follow standard ethical
        guidelines. Plagiarism in any form is strictly forbidden as is unethical use of privileged information by
        reviewers and meta reviewers, such as sharing this information or using it for any other purpose than the
        reviewing process. All suspected unethical behaviors will be investigated by an ethics board and individuals
        found violating the rules may face sanctions. This year, we will collect names of individuals that have been
        found to have violated these standards; if individuals representing conferences, journals, or other
        organizations request this list for decision making purposes, we may make this information available to them.
      </p>
      <p>
        The use of LLMs is allowed as a general-purpose writing assist tool. Authors should understand that they take
        full responsibility for the contents of their papers, including content generated by LLMs that could be
        construed as plagiarism or scientific misconduct (e.g., fabrication of facts). LLMs are not eligible for
        authorship.
      </p>
    </Fragment>
  </Content>
  <!-- 
  <Testimonials
    classes={{ container: 'py-0 md:py-0 lg:py-0 ' }}
    testimonials={[
      {
        title: 'Track 1',
        name: 'Attack Challenge',
        image: {
          src: '/track1.png',
          alt: 'Track 1',
        },
        link: '#TRACK1',
        job: 'Multimodal large language models (MLLMs), which are capable of processing images and performing visual question-and-answer tasks, may generate harmful content if the input image or text contains inducing or harmful properties. Furthermore, the introduction of perturbations to images or texts can degrade the performance of these models in various visual tasks, such as object counting and reasoning. This necessitates an investigation into the effects of different input perturbations or attack methods on the performance and trustworthiness of multimodal large models. Understanding these impacts is crucial for developing strategies to mitigate potential risks associated with MLLMs.',
      },
      {
        title: 'Track 2',
        name: 'Defense Challenge',
        image: {
          src: '/track2.png',
          alt: 'Track 2',
        },
        link: '#TRACK2',
        job: 'Multimodal Large Language Models (MLLMs) possess the capability to process images and perform visual question-and-answer tasks. However, when input images or texts contain malicious content or are subtly altered through perturbations, MLLMs can generate harmful responses or experience degraded performance across various visual tasks. This vulnerability represents a significant challenge to the trustworthiness and safety of MLLMs, underscoring the need for robust defense mechanisms. The primary goal of this challenge is to devise innovative strategies and techniques to safeguard MLLMs against attacks that leverage their multimodal capabilities.',
      },
      {
        title: 'Track 3',
        name: 'Agent Trustworthy Challenge',
        image: {
          src: '/track3.png',
          alt: 'Track 3',
        },
        link: '#TRACK3',
        job: "The evolution of Artificial Intelligence (AI) reflects its increasing capability and integration into our daily lives, from basic automated tools to sophisticated, autonomous systems. Initially, AI systems were simple agents performing goal-directed actions without specific human commands. Over time, these evolved into Large Language Models (LLMs) like GPT-4, which not only execute complex tasks but also enhance decision-making through advanced language understanding and generation capabilities. The most advanced tier of AI development includes ethically aligned, trustworthy agents. These agents are designed to operate reliably within ethical and safety frameworks, illustrating both the benefits and the essential need to manage the risks associated with AI's integration into society. This tiered framework—from basic agents, through linguistically skilled LLMs, to ethically guided trustworthy agents—underscores the progression and potential of AI in enhancing human capabilities and addressing complex challenges.",
      },
    ]}
  /> -->
  <Track1 title="MLLM Attack" tagline="Track I" id="TRACK1" />
  <!-- <Track2 title="Defense Challenge" tagline="Track 2" id="TRACK2" /> -->
  <Track3 title="Frontiers in Trustworthy Agents" tagline="Track II" id="TRACK2" />
  <FAQs
    title="Frequently Asked Questions"
    items={[
      {
        title: 'Can we submit a paper that will also be submitted to NeurIPS 2024?',
        description: 'Yes.',
        icon: 'tabler:help-octagon',
      },
      {
        title: 'Can we submit a paper that was accepted at ICLR 2024?',
        description: 'No. ICML prohibits main conference publication from appearing concurrently at the workshops.',
        icon: 'tabler:help-octagon',
      },
      {
        title: 'Will the reviews be made available to authors?',
        description: 'Yes.',
        icon: 'tabler:help-octagon',
      },
      {
        title: 'I have a question not addressed here, whom should I contact?',
        description: 'Email organizers at icmltifaworkshop@gmail.com',
        icon: 'tabler:help-octagon',
      },
    ]}
  />
</Layout>
